# ğŸ”§ YapÄ±landÄ±rma ve DaÄŸÄ±tÄ±m KÄ±lavuzu

Bu kÄ±lavuz, Nefret SuÃ§u Veri MadenciliÄŸi projesinin farklÄ± ortamlarda yapÄ±landÄ±rÄ±lmasÄ±, daÄŸÄ±tÄ±lmasÄ± ve Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± iÃ§in kapsamlÄ± talimatlar saÄŸlar.

## ğŸ“‹ Ã–n Gereksinimler

### Sistem Gereksinimleri
- **Ä°ÅŸletim Sistemi**: Windows 10/11, macOS 10.15+, veya Linux (Ubuntu 18.04+)
- **Bellek**: 16GB+ RAM Ã¶nerilen (8GB minimum)
- **Depolama**: 5GB boÅŸ disk alanÄ±
- **AÄŸ**: Paket indirmeleri iÃ§in internet baÄŸlantÄ±sÄ±

### YazÄ±lÄ±m BaÄŸÄ±mlÄ±lÄ±klarÄ±
- **Python**: 3.11 veya Ã¼zeri (performansÄ± optimize edilmiÅŸ)
- **Docker**: En son sÃ¼rÃ¼m (Ã¶nerilen)
- **Git**: Depo klonlama iÃ§in

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§ SeÃ§enekleri

### SeÃ§enek 1: Docker DaÄŸÄ±tÄ±mÄ± (Ã–nerilen)

Docker, en tutarlÄ± ve taÅŸÄ±nabilir daÄŸÄ±tÄ±m yÃ¶ntemini saÄŸlar.

#### AdÄ±m 1: Docker Kurulumu
```powershell
# Windows iÃ§in Docker Desktop indirin
# macOS iÃ§in Docker Desktop indirin
# Linux iÃ§in Docker Engine kurulumunu takip edin
```

#### AdÄ±m 2: Projeyi KlonlayÄ±n ve YapÄ±landÄ±rÄ±n
```bash
# Depoyu klonlayÄ±n
git clone <repository-url>
cd hate-crime-data-mining

# Docker imajÄ±nÄ± oluÅŸturun (optimize edilmiÅŸ Python 3.11)
docker build -t nefret-sucu-analiz .

# Konteyneri Ã§alÄ±ÅŸtÄ±rÄ±n (geliÅŸmiÅŸ yapÄ±landÄ±rma ile)
docker run -p 8888:8888 -v ${PWD}:/app --memory=8g nefret-sucu-analiz
```

#### AdÄ±m 3: Uygulamaya EriÅŸim
- **Ana Analiz**: `http://localhost:8888/tree/notebooks/nefret-sucu-analizi-tr.ipynb`
- **Ã–zet Rapor**: `http://localhost:8888/tree/notebooks/nefret-sucu-Ã¶zet.ipynb`
- **JupyterLab**: `http://localhost:8888/lab` (geliÅŸmiÅŸ arayÃ¼z)

### SeÃ§enek 2: Yerel Python Kurulumu

GeliÅŸtirme veya Ã¶zel ortamlar iÃ§in projeyi doÄŸrudan Python ile Ã§alÄ±ÅŸtÄ±rabilirsiniz.

#### AdÄ±m 1: Python OrtamÄ±nÄ± Kurun
```powershell
# Sanal ortam oluÅŸturun (Ã¶nerilen)
python -m venv nefret-sucu-env

# Sanal ortamÄ± etkinleÅŸtirin
# Windows:
nefret-sucu-env\Scripts\activate
# macOS/Linux:
source nefret-sucu-env/bin/activate
```

#### AdÄ±m 2: BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin
```bash
# Temel gereksinimleri yÃ¼kleyin (gÃ¼ncellenmiÅŸ ve optimize edilmiÅŸ)
pip install -r requirements.txt

# Jupyter Lab'Ä± baÅŸlatÄ±n (geliÅŸmiÅŸ arayÃ¼z)
jupyter lab notebooks/
```

#### AdÄ±m 3: Notebook'larÄ± Ã‡alÄ±ÅŸtÄ±rÄ±n
- **Ana Analiz**: `nefret-sucu-analizi-tr.ipynb` - DetaylÄ±, teknik analiz
- **Ã–zet Rapor**: `nefret-sucu-Ã¶zet.ipynb` - Konsantre, statik sonuÃ§lar

## ğŸ³ Docker YapÄ±landÄ±rma DetaylarÄ±

### GÃ¼ncellenmiÅŸ Dockerfile Ã–zellikleri
Proje, veri bilimi iÅŸ akÄ±ÅŸlarÄ± iÃ§in optimize edilmiÅŸ Ã§ok aÅŸamalÄ± Dockerfile iÃ§erir:

```dockerfile
# Python 3.11 ile optimize edilmiÅŸ performans
FROM python:3.11-slim as base

# Sistem baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± yÃ¼kle (derleyici ve kÃ¼tÃ¼phaneler)
RUN apt-get update && apt-get install -y \
    gcc g++ gfortran \
    libopenblas-dev liblapack-dev \
    pkg-config && \
    rm -rf /var/lib/apt/lists/*

# Ã‡alÄ±ÅŸma dizinini ayarla
WORKDIR /app

# Python paketlerini optimize edilmiÅŸ ÅŸekilde yÃ¼kle
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Proje dosyalarÄ±nÄ± kopyala
COPY . .

# JupyterLab portunu aÃ§ (gÃ¼venlik ile)
EXPOSE 8888

# TÃ¼rkÃ§e dil desteÄŸi ve optimize edilmiÅŸ JupyterLab baÅŸlatma
ENV LANG=tr_TR.UTF-8
CMD ["jupyter", "lab", "--ip=0.0.0.0", "--port=8888", "--no-browser", \
     "--allow-root", "--NotebookApp.token=''", "--NotebookApp.password=''", \
     "--notebook-dir=/app/notebooks"]
```

### Ã–zelleÅŸtirilmiÅŸ Docker KomutlarÄ±

#### GeliÅŸtirme Modu
```bash
# GeliÅŸtirme iÃ§in hacim baÄŸlama ile Ã§alÄ±ÅŸtÄ±r
docker run -p 8888:8888 -v ${PWD}:/app --name nefret-analiz-dev nefret-sucu-analiz

# Bellek limitleri ile Ã§alÄ±ÅŸtÄ±r (bÃ¼yÃ¼k veri setleri iÃ§in)
docker run -p 8888:8888 --memory=16g --cpus=8 nefret-sucu-analiz
```

#### Ãœretim Modu
```bash
# Arka plan servisi olarak Ã§alÄ±ÅŸtÄ±r
docker run -d -p 8888:8888 --name nefret-sucu-servisi --restart=always nefret-sucu-analiz

# Servis durumunu kontrol et
docker logs nefret-sucu-servisi

# Servisi durdur
docker stop nefret-sucu-servisi
```

## ğŸ“¦ Paket BaÄŸÄ±mlÄ±lÄ±klarÄ±

### Temel Gereksinimler (requirements.txt)
GÃ¼ncellenmiÅŸ ve optimize edilmiÅŸ paket listesi:

```python
# === Temel Veri Ä°ÅŸleme (Base Data Processing) ===
pandas>=2.1.0                 # GeliÅŸmiÅŸ veri manipÃ¼lasyonu
numpy>=1.24.0                 # SayÄ±sal hesaplamalar
scipy>=1.11.0                 # Ä°statistiksel hesaplamalar

# === Makine Ã–ÄŸrenmesi (Machine Learning) ===
scikit-learn>=1.3.0          # ML algoritmalarÄ± ve araÃ§larÄ±
xgboost>=1.7.0               # Gradient boosting
imbalanced-learn>=0.11.0     # Dengesiz veri kÃ¼meleri

# === GÃ¶rselleÅŸtirme (Visualization) ===
matplotlib>=3.7.0            # Temel grafikler
seaborn>=0.12.0              # Ä°statistiksel gÃ¶rselleÅŸtirme
plotly>=5.15.0               # Ä°nteraktif grafikler
wordcloud>=1.9.0             # Kelime bulutlarÄ±

# === Notebook OrtamÄ± (Notebook Environment) ===
jupyterlab>=4.0.0            # Modern notebook arayÃ¼zÃ¼
ipywidgets>=8.1.0            # Ä°nteraktif widget'lar
ipython>=8.14.0              # GeliÅŸmiÅŸ Python shell

# === GeliÅŸmiÅŸ Analitik (Advanced Analytics) ===
networkx>=3.1.0              # AÄŸ analizi
mlxtend>=0.22.0              # Birliktelik kurallarÄ±
statsmodels>=0.14.0          # Ä°statistiksel modelleme
```

### Performans ve GÃ¼venlik OptimizasyonlarÄ±
```python
# === Performans (Performance) ===
numba>=0.57.0                # JIT derleme ile hÄ±zlandÄ±rma
joblib>=1.3.0                # Paralel iÅŸleme
dask>=2023.7.0               # BÃ¼yÃ¼k veri iÅŸleme

# === GÃ¼venlik ve Kalite (Security & Quality) ===
bandit>=1.7.0                # GÃ¼venlik analizi
safety>=2.3.0                # GÃ¼venlik aÃ§Ä±ÄŸÄ± taramasÄ±
```

## ğŸ”§ Ortam YapÄ±landÄ±rmasÄ±

### JupyterLab YapÄ±landÄ±rmasÄ±
Optimal performans iÃ§in Ã¶zel JupyterLab yapÄ±landÄ±rmasÄ±:

```python
# jupyter_lab_config.py
c.ServerApp.ip = '0.0.0.0'
c.ServerApp.port = 8888
c.ServerApp.open_browser = False
c.ServerApp.allow_root = True
c.ServerApp.token = ''
c.ServerApp.password = ''
c.ServerApp.notebook_dir = '/app/notebooks'

# TÃ¼rkÃ§e dil desteÄŸi
c.ServerApp.tornado_settings = {
    'headers': {
        'Content-Language': 'tr-TR',
    }
}
```

### Ortam DeÄŸiÅŸkenleri
YapÄ±landÄ±rma iÃ§in ortam deÄŸiÅŸkenlerini ayarlayÄ±n:

```bash
# .env dosyasÄ±
JUPYTER_PORT=8888
DATA_PATH=./hate-crime_2017-2025.csv
RESULTS_PATH=./results/
LOG_LEVEL=INFO
PYTHONPATH=/app
LANG=tr_TR.UTF-8
```

## ğŸ” Sorun Giderme

### YaygÄ±n Sorunlar ve Ã‡Ã¶zÃ¼mleri

#### Docker SorunlarÄ±

**Sorun**: Docker konteyneri baÅŸlatÄ±lamÄ±yor
```powershell
# Docker servis durumunu kontrol edin
docker --version
docker ps

# Konteyner gÃ¼nlÃ¼klerini gÃ¶rÃ¼ntÃ¼leyin
docker logs <container-id>

# Ä°majÄ± yeniden oluÅŸturun
docker build --no-cache -t nefret-sucu-analiz .
```

**Sorun**: 8888 portu zaten kullanÄ±mda
```powershell
# FarklÄ± port kullanÄ±n
docker run -p 8889:8888 nefret-sucu-analiz

# Veya mevcut iÅŸlemi sonlandÄ±rÄ±n
# Windows:
netstat -ano | findstr :8888
taskkill /PID <PID> /F

# macOS/Linux:
lsof -ti:8888 | xargs kill -9
```

#### Python Kurulum SorunlarÄ±

**Sorun**: Paket kurulum hatalarÄ±
```bash
# pip'i gÃ¼ncelleyin
pip install --upgrade pip

# AyrÄ±ntÄ±lÄ± Ã§Ä±ktÄ± ile yÃ¼kleyin
pip install -r requirements.txt -v

# Alternatif olarak conda kullanÄ±n
conda install --file requirements.txt
```

**Sorun**: Analiz sÄ±rasÄ±nda bellek hatalarÄ±
```python
# Test iÃ§in veri kÃ¼mesi boyutunu azaltÄ±n
df_sample = df.sample(n=1000, random_state=42)

# BÃ¼yÃ¼k iÅŸlemler iÃ§in parÃ§alama kullanÄ±n
for chunk in pd.read_csv('data.csv', chunksize=5000):
    process_chunk(chunk)

# Bellek kullanÄ±mÄ±nÄ± optimize edin
import gc
gc.collect()
```

#### Notebook SorunlarÄ±

**Sorun**: Kernel Ã§Ã¶kÃ¼yor veya yeniden baÅŸlÄ±yor
- Bellek tahsisini artÄ±rÄ±n
- Kernel'i yeniden baÅŸlatÄ±n ve hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n
- Sonsuz dÃ¶ngÃ¼ veya bellek sÄ±zÄ±ntÄ±larÄ±nÄ± kontrol edin

**Sorun**: GÃ¶rselleÅŸtirmeler eksik
```bash
# Ek backend'leri yÃ¼kleyin
pip install ipympl
jupyter nbextension enable --py widgetsnbextension
jupyter labextension install @jupyter-widgets/jupyterlab-manager
```

## ğŸ“Š Performans Optimizasyonu

### Bellek YÃ¶netimi
```python
# Bellek kullanÄ±mÄ±nÄ± izleyin
import psutil
import pandas as pd

def check_memory():
    memory = psutil.virtual_memory()
    print(f"Toplam bellek: {memory.total / (1024**3):.1f} GB")
    print(f"KullanÄ±m: {memory.percent}%")
    print(f"Mevcut: {memory.available / (1024**3):.1f} GB")

# BÃ¼yÃ¼k deÄŸiÅŸkenleri temizleyin
def cleanup_memory(*vars_to_delete):
    for var in vars_to_delete:
        if var in globals():
            del globals()[var]
    import gc
    gc.collect()
```

### Hesaplama Optimizasyonu
```python
# Paralel iÅŸleme kullanÄ±n
from joblib import Parallel, delayed
import multiprocessing

def parallel_process(func, data_list, n_jobs=-1):
    """Paralel iÅŸleme iÃ§in yardÄ±mcÄ± fonksiyon"""
    if n_jobs == -1:
        n_jobs = multiprocessing.cpu_count()
    
    results = Parallel(n_jobs=n_jobs)(
        delayed(func)(item) for item in data_list
    )
    return results

# Pandas iÅŸlemlerini optimize edin
def optimize_dataframe(df):
    """DataFrame'i bellek iÃ§in optimize et"""
    for col in df.select_dtypes(include=['object']):
        if df[col].nunique() < len(df) * 0.5:
            df[col] = df[col].astype('category')
    
    for col in df.select_dtypes(include=['int64']):
        if df[col].min() >= 0 and df[col].max() < 255:
            df[col] = df[col].astype('uint8')
        elif df[col].min() >= -128 and df[col].max() < 127:
            df[col] = df[col].astype('int8')
    
    return df
```

## ğŸ§ª Test ve DoÄŸrulama

### Veri DoÄŸrulama
```python
def validate_hate_crime_data(df):
    """Nefret suÃ§u verilerini doÄŸrula"""
    
    # Temel doÄŸrulamalar
    assert df.shape[0] > 0, "Veri kÃ¼mesi boÅŸ"
    assert 'Date of Incident' in df.columns, "Olay tarihi sÃ¼tunu eksik"
    assert 'Bias' in df.columns, "Ã–nyargÄ± sÃ¼tunu eksik"
    
    # Tarih doÄŸrulamasÄ±
    date_nulls = df['Date of Incident'].isna().sum()
    if date_nulls > 0:
        print(f"UyarÄ±: {date_nulls} eksik tarih bulundu")
    
    # Ã–nyargÄ± tÃ¼rÃ¼ doÄŸrulamasÄ±
    bias_nulls = df['Bias'].isna().sum()
    if bias_nulls > 0:
        print(f"UyarÄ±: {bias_nulls} eksik Ã¶nyargÄ± etiketi bulundu")
    
    # YÄ±l aralÄ±ÄŸÄ± doÄŸrulamasÄ±
    years = pd.to_datetime(df['Date of Incident']).dt.year
    print(f"Veri aralÄ±ÄŸÄ±: {years.min()} - {years.max()}")
    
    return True

# KullanÄ±m
# validate_hate_crime_data(df)
```

### Model Testi
```python
def comprehensive_model_test(model, X, y):
    """KapsamlÄ± model testi"""
    from sklearn.model_selection import cross_val_score, StratifiedKFold
    from sklearn.metrics import classification_report
    
    # Ã‡apraz doÄŸrulama
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')
    
    print(f"Ã‡apraz DoÄŸrulama SonuÃ§larÄ±:")
    print(f"Ortalama DoÄŸruluk: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
    print(f"Minimum DoÄŸruluk: {cv_scores.min():.3f}")
    print(f"Maksimum DoÄŸruluk: {cv_scores.max():.3f}")
    
    return cv_scores
```

## ğŸ“ Proje YapÄ±sÄ± DoÄŸrulamasÄ±

Proje yapÄ±nÄ±zÄ±n ÅŸu ÅŸekilde olduÄŸundan emin olun:
```
hate-crime-data-mining/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ nefret-sucu-analizi-tr.ipynb    # Ana detaylÄ± analiz
â”‚   â”œâ”€â”€ nefret-sucu-Ã¶zet.ipynb          # Konsantre Ã¶zet rapor
â”‚   â””â”€â”€ hate-crime.ipynb                # Orijinal Ä°ngilizce analiz
â”œâ”€â”€ hate-crime_2017-2025.csv            # Veri kÃ¼mesi
â”œâ”€â”€ hate-crime.png                      # Proje gÃ¶rseli
â”œâ”€â”€ requirements.txt                     # GÃ¼ncellenmiÅŸ baÄŸÄ±mlÄ±lÄ±klar
â”œâ”€â”€ Dockerfile                          # Optimize edilmiÅŸ konteyner
â”œâ”€â”€ README.md                           # Proje dokÃ¼mantasyonu
â”œâ”€â”€ BUILD.md                            # Bu yapÄ±landÄ±rma kÄ±lavuzu
â”œâ”€â”€ Nefret_Sucu_Analiz_Raporu_2017-2025.md  # DetaylÄ± rapor
â””â”€â”€ .env                                # Ortam deÄŸiÅŸkenleri (opsiyonel)
```

## ğŸš€ DaÄŸÄ±tÄ±m SeÃ§enekleri

### Bulut DaÄŸÄ±tÄ±mÄ±

#### Google Colab
```python
# Colab'da kurulum iÃ§in ilk hÃ¼crede:
!pip install -r requirements.txt
!pip install --upgrade pandas scikit-learn plotly

# TÃ¼rkÃ§e dil desteÄŸi
import locale
locale.setlocale(locale.LC_ALL, 'tr_TR.UTF-8')
```

#### Azure Machine Learning
```python
# Azure ML ortamÄ± iÃ§in
from azureml.core import Environment, ScriptRunConfig
from azureml.core.conda_dependencies import CondaDependencies

# Conda baÄŸÄ±mlÄ±lÄ±klarÄ±
conda_deps = CondaDependencies.create(pip_packages=[
    'pandas>=2.1.0',
    'scikit-learn>=1.3.0',
    'plotly>=5.15.0',
    'jupyterlab>=4.0.0'
])

# Ortam oluÅŸtur
env = Environment(name='nefret-sucu-analiz')
env.python.conda_dependencies = conda_deps
```

#### AWS SageMaker
```python
# SageMaker notebook instance yapÄ±landÄ±rmasÄ±
{
    "NotebookInstanceType": "ml.t3.xlarge",
    "RoleArn": "arn:aws:iam::account:role/SageMakerRole",
    "DefaultCodeRepository": "https://github.com/user/hate-crime-data-mining"
}
```

### Yerel Sunucu DaÄŸÄ±tÄ±mÄ±
```bash
# Windows GÃ¶rev ZamanlayÄ±cÄ±sÄ± iÃ§in PowerShell betiÄŸi
# nefret-sucu-service.ps1

$env:PYTHONPATH = "C:\path\to\hate-crime-data-mining"
Set-Location "C:\path\to\hate-crime-data-mining"

# Sanal ortamÄ± etkinleÅŸtir
& ".\nefret-sucu-env\Scripts\Activate.ps1"

# JupyterLab'Ä± baÅŸlat
jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --notebook-dir=notebooks
```

## ğŸ“ BakÄ±m ve GÃ¼ncellemeler

### BaÄŸÄ±mlÄ±lÄ±klarÄ± GÃ¼ncelleme
```bash
# TÃ¼m paketleri gÃ¼ncelle
pip install --upgrade -r requirements.txt

# Belirli paketleri gÃ¼ncelle
pip install --upgrade pandas scikit-learn plotly jupyterlab

# GÃ¼venlik aÃ§Ä±ÄŸÄ± kontrolÃ¼
pip audit
bandit -r notebooks/
```

### Veri GÃ¼ncellemeleri
```python
def validate_new_data_schema(df_new, df_reference):
    """Yeni veri formatÄ±nÄ± doÄŸrula"""
    
    required_columns = df_reference.columns.tolist()
    missing_columns = set(required_columns) - set(df_new.columns)
    
    if missing_columns:
        raise ValueError(f"Eksik sÃ¼tunlar: {missing_columns}")
    
    # Veri tÃ¼rÃ¼ kontrolÃ¼
    for col in required_columns:
        if df_new[col].dtype != df_reference[col].dtype:
            print(f"UyarÄ±: {col} sÃ¼tunu veri tÃ¼rÃ¼ farklÄ±")
    
    return True

# KullanÄ±m Ã¶rneÄŸi
# validate_new_data_schema(new_df, df)
```

## ğŸ”’ GÃ¼venlik KonularÄ±

### Veri GizliliÄŸi
- Veri kÃ¼melerinde kiÅŸisel tanÄ±mlayÄ±cÄ± bilgi (PII) olmadÄ±ÄŸÄ±ndan emin olun
- TÃ¼m analizler iÃ§in anonimleÅŸtirilmiÅŸ veri kullanÄ±n
- Hassas sonuÃ§lar iÃ§in eriÅŸim kontrolleri uygulayÄ±n

### Jupyter GÃ¼venliÄŸi
```python
# GÃ¼venli token oluÅŸtur
from jupyter_server.auth import passwd
passwd()  # OluÅŸturulan hash'i yapÄ±landÄ±rmada kullanÄ±n
```

### Docker GÃ¼venliÄŸi
```dockerfile
# Root olmayan kullanÄ±cÄ± olarak Ã§alÄ±ÅŸtÄ±r
RUN useradd -m -s /bin/bash jupyter
USER jupyter

# GÃ¼venlik gÃ¼ncellemeleri
RUN apt-get update && apt-get upgrade -y && \
    apt-get clean && rm -rf /var/lib/apt/lists/*
```

## ğŸ“ Destek ve Kaynaklar

### YardÄ±m Alma
- **DokÃ¼mantasyon**: Proje genel bakÄ±ÅŸÄ± iÃ§in README.md'yi kontrol edin
- **Sorunlar**: Hata veya sorular iÃ§in GitHub issue'larÄ± oluÅŸturun
- **Topluluk**: GeniÅŸ destek iÃ§in veri bilimi topluluklarÄ±na katÄ±lÄ±n

### Ek Kaynaklar
- [Pandas DokÃ¼mantasyonu](https://pandas.pydata.org/docs/)
- [Scikit-learn KullanÄ±cÄ± KÄ±lavuzu](https://scikit-learn.org/stable/user_guide.html)
- [Plotly DokÃ¼mantasyonu](https://plotly.com/python/)
- [JupyterLab DokÃ¼mantasyonu](https://jupyterlab.readthedocs.io/)
- [Docker DokÃ¼mantasyonu](https://docs.docker.com/)

### TÃ¼rkÃ§e Kaynaklar
- **Veri Bilimi**: Python ile veri analizi ve makine Ã¶ÄŸrenmesi
- **Ä°statistik**: Temel istatistiksel kavramlar ve testler
- **GÃ¶rselleÅŸtirme**: Etkili grafik tasarÄ±mÄ± prensipleri

---

**Son GÃ¼ncelleme**: AralÄ±k 2024  
**SÃ¼rÃ¼m**: 2.0  
**BakÄ±m**: Proje Ekibi  
**Dil**: TÃ¼rkÃ§e (Teknik terimler Ä°ngilizce korunmuÅŸtur)
